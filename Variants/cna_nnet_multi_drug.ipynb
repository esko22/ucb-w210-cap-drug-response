{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Install TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cna_efgr = pd.read_csv(\"../data/cna_ic50_Erlotinib_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "cna_pacl = pd.read_csv(\"../data/cna_ic50_Paclitaxel_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "cna_suni = pd.read_csv(\"../data/cna_ic50_Sunitinib_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "cna_sora = pd.read_csv(\"../data/cna_ic50_Sorafenib_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "cna_rapa = pd.read_csv(\"../data/cna_ic50_Rapamycin_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cna_multi_drug = pd.concat([cna_efgr, cna_pacl, cna_suni, cna_sora,cna_rapa], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>107161145</th>\n",
       "      <th>107985535</th>\n",
       "      <th>107986809</th>\n",
       "      <th>107987337</th>\n",
       "      <th>107987341</th>\n",
       "      <th>109731405</th>\n",
       "      <th>112441434</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>LN_IC50</th>\n",
       "      <th>BINARY_RESPONSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COSMIC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1240128</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.632372</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240173</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>1</td>\n",
       "      <td>3.323416</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240181</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.584963</td>\n",
       "      <td>-1.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.836213</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240182</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.584963</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>1</td>\n",
       "      <td>2.717111</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240183</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508283</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0         1         2         9        10        12  \\\n",
       "COSMIC_ID                                                                 \n",
       "1240128             0 -0.584963  0.415037 -0.584963 -0.584963  0.000000   \n",
       "1240173             1  0.000000 -0.415037  0.321928  0.321928 -0.415037   \n",
       "1240181             2  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1240182             3  0.000000  0.415037  0.415037  0.415037  0.415037   \n",
       "1240183             4 -0.415037  0.000000 -1.000000 -1.000000  0.000000   \n",
       "\n",
       "                 13        14        15        16  ...  107161145  107985535  \\\n",
       "COSMIC_ID                                          ...                         \n",
       "1240128    0.000000  0.000000  0.000000  0.000000  ...   0.000000  -0.584963   \n",
       "1240173    0.321928  0.000000  0.000000 -0.415037  ...   0.000000   0.000000   \n",
       "1240181    0.000000  0.000000  0.000000  0.000000  ...   0.000000   0.000000   \n",
       "1240182    0.415037  0.000000  0.415037 -0.584963  ...   0.000000   0.000000   \n",
       "1240183    0.000000 -0.415037  0.000000 -0.415037  ...   0.321928   0.321928   \n",
       "\n",
       "           107986809  107987337  107987341  109731405  112441434  DRUG_ID  \\\n",
       "COSMIC_ID                                                                   \n",
       "1240128     0.000000  -4.320000  -4.320000   0.000000   0.000000        1   \n",
       "1240173     0.321928  -4.320000  -4.320000  -0.415037  -0.415037        1   \n",
       "1240181     0.000000  -1.584963  -1.584963   0.000000   0.000000        1   \n",
       "1240182     0.000000  -1.584963  -4.320000  -0.584963  -0.584963        1   \n",
       "1240183     0.000000  -4.320000  -4.320000  -0.415037   0.321928        1   \n",
       "\n",
       "            LN_IC50  BINARY_RESPONSE  \n",
       "COSMIC_ID                             \n",
       "1240128    2.632372                R  \n",
       "1240173    3.323416                R  \n",
       "1240181    2.836213                R  \n",
       "1240182    2.717111                R  \n",
       "1240183    0.508283                S  \n",
       "\n",
       "[5 rows x 24431 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cna_multi_drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kbloom/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>107133524</th>\n",
       "      <th>107161145</th>\n",
       "      <th>107985535</th>\n",
       "      <th>107986809</th>\n",
       "      <th>107987337</th>\n",
       "      <th>107987341</th>\n",
       "      <th>109731405</th>\n",
       "      <th>112441434</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>BINARY_RESPONSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COSMIC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1240128</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.584963</td>\n",
       "      <td>-1.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.584963</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>-0.584963</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240183</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24429 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1         2         9        10        12        13  \\\n",
       "COSMIC_ID                                                               \n",
       "1240128   -0.584963  0.415037 -0.584963 -0.584963  0.000000  0.000000   \n",
       "1240173    0.000000 -0.415037  0.321928  0.321928 -0.415037  0.321928   \n",
       "1240181    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1240182    0.000000  0.415037  0.415037  0.415037  0.415037  0.415037   \n",
       "1240183   -0.415037  0.000000 -1.000000 -1.000000  0.000000  0.000000   \n",
       "\n",
       "                 14        15        16        18  ...  107133524  107161145  \\\n",
       "COSMIC_ID                                          ...                         \n",
       "1240128    0.000000  0.000000  0.000000  0.000000  ...  -0.584963   0.000000   \n",
       "1240173    0.000000  0.000000 -0.415037 -0.415037  ...   0.000000   0.000000   \n",
       "1240181    0.000000  0.000000  0.000000  0.000000  ...   0.000000   0.000000   \n",
       "1240182    0.000000  0.415037 -0.584963  0.000000  ...   0.415037   0.000000   \n",
       "1240183   -0.415037  0.000000 -0.415037 -0.415037  ...   0.321928   0.321928   \n",
       "\n",
       "           107985535  107986809  107987337  107987341  109731405  112441434  \\\n",
       "COSMIC_ID                                                                     \n",
       "1240128    -0.584963   0.000000  -4.320000  -4.320000   0.000000   0.000000   \n",
       "1240173     0.000000   0.321928  -4.320000  -4.320000  -0.415037  -0.415037   \n",
       "1240181     0.000000   0.000000  -1.584963  -1.584963   0.000000   0.000000   \n",
       "1240182     0.000000   0.000000  -1.584963  -4.320000  -0.584963  -0.584963   \n",
       "1240183     0.321928   0.000000  -4.320000  -4.320000  -0.415037   0.321928   \n",
       "\n",
       "           DRUG_ID  BINARY_RESPONSE  \n",
       "COSMIC_ID                            \n",
       "1240128          1                0  \n",
       "1240173          1                0  \n",
       "1240181          1                0  \n",
       "1240182          1                0  \n",
       "1240183          1                1  \n",
       "\n",
       "[5 rows x 24429 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cna_multi_drug)\n",
    "\n",
    "cna_multi_drug = cna_multi_drug.drop('LN_IC50', axis=1)\n",
    "cna_multi_drug = cna_multi_drug.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "cna_multi_drug.loc[(cna_multi_drug.BINARY_RESPONSE == 'S'),'BINARY_RESPONSE'] = 1\n",
    "cna_multi_drug.loc[(cna_multi_drug.BINARY_RESPONSE == 'R'),'BINARY_RESPONSE'] = 0\n",
    "\n",
    "cna_multi_drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_data_set, dev_data_set, train_labels, dev_labels = train_test_split(cna_multi_drug, cna_multi_drug['BINARY_RESPONSE'], test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = wes_multi_drug.pop('BINARY_RESPONSE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data_set.values, train_labels.values))\n",
    "train_dataset = train_dataset.shuffle(len(train_data_set)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((dev_data_set.values, dev_labels.values))\n",
    "test_dataset = test_dataset.shuffle(len(dev_data_set)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  #tf.keras.layers.Flatten(input_shape=(18384,)),\n",
    "  tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train for 90 steps\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 4.2988 - accuracy: 0.7778\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 5.2112 - accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.5472 - accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 5.3535 - accuracy: 0.7333\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 4.7414 - accuracy: 0.7778\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.0556 - accuracy: 0.8111\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.0501 - accuracy: 0.8444\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.7745 - accuracy: 0.7556\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 1.7392 - accuracy: 0.7778\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.0152 - accuracy: 0.8111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a41927c10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10, steps_per_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 - 1s - loss: 1.0584 - accuracy: 0.8247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0583661399617916, 0.82474226]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset, verbose=2, steps=len(dev_data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  3127040   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 3,128,330\n",
      "Trainable params: 3,128,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kbloom/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: cna_multi_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('cna_multi_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 18384)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               2353280   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,354,570\n",
      "Trainable params: 2,354,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('wes_multi_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_url = \"cna_multi_model/\"\n",
    "embed = hub.KerasLayer(hub_url, input_shape=(24429,), dtype=tf.float64, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotha_model = tf.keras.Sequential([\n",
    "    embed,\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotha_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 150 steps, validate for 388 steps\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.3978 - accuracy: 0.8533 - val_loss: 0.2761 - val_accuracy: 0.9227\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3804 - accuracy: 0.8667 - val_loss: 0.2784 - val_accuracy: 0.9227\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3920 - accuracy: 0.8667 - val_loss: 0.2777 - val_accuracy: 0.9227\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3164 - accuracy: 0.8933 - val_loss: 0.2740 - val_accuracy: 0.9227\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2604 - accuracy: 0.9400 - val_loss: 0.2665 - val_accuracy: 0.9227\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.8400 - val_loss: 0.2716 - val_accuracy: 0.9227\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2934 - accuracy: 0.9133 - val_loss: 0.2680 - val_accuracy: 0.9227\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3167 - accuracy: 0.9000 - val_loss: 0.2668 - val_accuracy: 0.9227\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4071 - accuracy: 0.8533 - val_loss: 0.2694 - val_accuracy: 0.9227\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3705 - accuracy: 0.8667 - val_loss: 0.2742 - val_accuracy: 0.9227\n"
     ]
    }
   ],
   "source": [
    "history = anotha_model.fit(train_dataset, epochs=10, steps_per_epoch=150, validation_data=(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a68c185d0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 - 1s - loss: 0.2742 - accuracy: 0.9227\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = anotha_model.evaluate(test_dataset, verbose=2, steps=len(dev_data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = []\n",
    "for layer in anotha_model.layers:\n",
    "   w = layer.get_weights()\n",
    "   all_weights.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92268044\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[-0.04909669, -0.01523309, -0.01865687, ..., -0.01055465,\n",
      "         0.01344721, -0.02748404],\n",
      "       [-0.03641999, -0.02685677,  0.00290082, ..., -0.03744866,\n",
      "        -0.0090578 , -0.04769251],\n",
      "       [ 0.00803957, -0.00854779,  0.02295541, ..., -0.0115859 ,\n",
      "         0.02968053,  0.03313942],\n",
      "       ...,\n",
      "       [-0.0318936 , -0.00824761, -0.01459652, ...,  0.03438311,\n",
      "         0.02144709,  0.04907155],\n",
      "       [-0.07699451, -0.02163057, -0.05207279, ..., -0.04741478,\n",
      "        -0.02081542, -0.003164  ],\n",
      "       [ 0.01142061, -0.06648941, -0.01294564, ..., -0.00021745,\n",
      "         0.02926855,  0.06726924]], dtype=float32), array([-0.05742534, -0.02629478, -0.05400872, -0.03673787, -0.03749199,\n",
      "       -0.04593214, -0.0265057 ,  0.00884796, -0.02059793, -0.01546956,\n",
      "       -0.01579989,  0.03631994, -0.0211074 , -0.00523069, -0.02447747,\n",
      "       -0.02517388, -0.02245427,  0.04299168,  0.00242443, -0.02518057,\n",
      "       -0.00963164, -0.03565749, -0.0485021 , -0.0081458 , -0.02202019,\n",
      "       -0.01815645, -0.00275129, -0.02112816, -0.00997643,  0.03293157,\n",
      "       -0.03427157, -0.01531102, -0.00883981,  0.02232946, -0.01815844,\n",
      "        0.00046296,  0.00934611, -0.0128424 , -0.03533312,  0.0288438 ,\n",
      "        0.03057649, -0.02544249, -0.00926495, -0.01422388,  0.00994601,\n",
      "       -0.00095294, -0.01962949, -0.03256995, -0.02554223, -0.02049702,\n",
      "        0.03541911, -0.03294657, -0.02036215, -0.03469769, -0.03555188,\n",
      "       -0.01724338,  0.0221031 , -0.01673909, -0.00549971, -0.02598106,\n",
      "       -0.03271557, -0.02173711, -0.00949725, -0.01372632, -0.01634246,\n",
      "       -0.00758679, -0.00555816, -0.03121121, -0.00570571, -0.0431219 ,\n",
      "       -0.00691709, -0.00797706,  0.04248619, -0.048873  ,  0.00795928,\n",
      "        0.02441882, -0.03138614, -0.02341582, -0.02330945, -0.04282226,\n",
      "        0.02693077, -0.04171034, -0.00977274, -0.01832903, -0.01721507,\n",
      "       -0.03603548, -0.03327122, -0.00814734,  0.04504726, -0.01919135,\n",
      "       -0.02531719, -0.01974489, -0.01704971, -0.0291389 , -0.0264962 ,\n",
      "        0.006937  , -0.02514125,  0.02305325, -0.03749617, -0.0613166 ,\n",
      "        0.02784723, -0.02679374, -0.02246676, -0.0276785 , -0.00234073,\n",
      "       -0.0572926 , -0.04558457,  0.00801017, -0.02620311, -0.02918199,\n",
      "       -0.02330669, -0.00971191, -0.0137579 , -0.03420676, -0.04456811,\n",
      "       -0.03232602, -0.0125249 , -0.03602039, -0.01601662,  0.0232993 ,\n",
      "        0.00077768,  0.02747161, -0.03067147, -0.01210041, -0.02567914,\n",
      "       -0.04782668, -0.04152166, -0.04841598], dtype=float32), array([[-0.10023954,  0.04509757,  0.0737628 , ...,  0.11874816,\n",
      "         0.027289  ,  0.05558771],\n",
      "       [ 0.15539137,  0.03924974, -0.15740444, ..., -0.17952171,\n",
      "        -0.11340764,  0.03167783],\n",
      "       [-0.14080466,  0.02054942,  0.12227742, ..., -0.08001861,\n",
      "        -0.01661868, -0.03603261],\n",
      "       ...,\n",
      "       [-0.1417374 ,  0.15045236,  0.06220042, ...,  0.08133408,\n",
      "        -0.02731406,  0.18519467],\n",
      "       [-0.10520983,  0.01730158,  0.12923147, ...,  0.06602874,\n",
      "        -0.17352304, -0.1840499 ],\n",
      "       [-0.01889049,  0.10258984,  0.00074262, ..., -0.2059711 ,\n",
      "         0.05168214,  0.1204089 ]], dtype=float32), array([ 0.02121261, -0.01023491, -0.01645555, -0.04114162, -0.07886158,\n",
      "       -0.06533574, -0.02389302, -0.05223415, -0.03252885, -0.04331585],\n",
      "      dtype=float32)], [array([[ 0.05339677, -0.28208268, -0.38750345,  0.3857433 ,  0.6003391 ,\n",
      "         0.15158202, -0.06611395, -0.42923903, -0.43789637, -0.24881768,\n",
      "         0.427737  ,  0.25328258, -0.4215076 ,  0.5652217 ,  0.55483305,\n",
      "         0.1127739 ],\n",
      "       [ 0.13857268, -0.43925846,  0.44140244, -0.33166316, -0.33745292,\n",
      "        -0.2482833 , -0.21587443, -0.32937774, -0.07741775, -0.11892582,\n",
      "         0.48195365,  0.24559888, -0.09543815,  0.01421898,  0.3472261 ,\n",
      "         0.33523402],\n",
      "       [-0.14200704,  0.22471376,  0.16691372,  0.48344857,  0.31466645,\n",
      "        -0.3564201 ,  0.38650247,  0.09493072,  0.40405968,  0.46564138,\n",
      "         0.03732698,  0.27206933, -0.21371174, -0.28005373, -0.41961777,\n",
      "         0.40479007],\n",
      "       [ 0.3003994 , -0.2706405 , -0.29539648, -0.19784747,  0.42791876,\n",
      "        -0.35838735,  0.43892014, -0.15681034,  0.03410894,  0.16321647,\n",
      "         0.0292066 , -0.478464  , -0.10132629,  0.49657196, -0.4428356 ,\n",
      "        -0.30859935],\n",
      "       [ 0.21452321, -0.00409891,  0.1739513 , -0.08020128,  0.3282488 ,\n",
      "        -0.22288652, -0.2051958 ,  0.14933477,  0.47489968, -0.2180694 ,\n",
      "         0.46629614,  0.09495244, -0.15119663, -0.15540518, -0.25793567,\n",
      "         0.38641593],\n",
      "       [ 0.39712027, -0.38863373, -0.36162013, -0.41676888, -0.38240498,\n",
      "        -0.00563187, -0.1656528 ,  0.43673325,  0.12806259,  0.32584712,\n",
      "        -0.03552926,  0.15299197,  0.30046663,  0.36713898,  0.36147383,\n",
      "         0.14990029],\n",
      "       [-0.13175969,  0.35308886,  0.10558799,  0.268761  ,  0.41864902,\n",
      "         0.18713588,  0.41255882,  0.4666872 , -0.43319282,  0.41165382,\n",
      "        -0.44572908, -0.3492433 ,  0.05455565, -0.13084373,  0.3610212 ,\n",
      "         0.05075477],\n",
      "       [-0.44997913,  0.26493275,  0.16177762,  0.19858532, -0.3883249 ,\n",
      "        -0.01331415,  0.43232512, -0.06219417, -0.21751821, -0.258476  ,\n",
      "         0.42072204,  0.25195065,  0.30338264,  0.14223732, -0.13181928,\n",
      "         0.3181516 ],\n",
      "       [ 0.0382523 ,  0.47143143, -0.47678736,  0.35636646, -0.01531709,\n",
      "        -0.40732843, -0.3577706 , -0.09742543, -0.34686077,  0.48226467,\n",
      "         0.2883552 , -0.44382024, -0.24979912,  0.21365997, -0.15593657,\n",
      "         0.05498811],\n",
      "       [ 0.05350183,  0.2801845 , -0.05035105,  0.2422131 , -0.21644634,\n",
      "         0.22732684, -0.34097216, -0.4201607 , -0.17863324,  0.34688914,\n",
      "        -0.32772592,  0.18738788,  0.07256305,  0.00459682,  0.2885951 ,\n",
      "        -0.00798471]], dtype=float32), array([-0.0721888 ,  0.02558221, -0.03432493,  0.25833344,  0.3287996 ,\n",
      "       -0.15772161, -0.00225156, -0.02754973,  0.01821325,  0.02515171,\n",
      "        0.30367997, -0.187948  , -0.01298944,  0.25343037,  0.24837512,\n",
      "       -0.11320972], dtype=float32)], [array([[ 0.44203153],\n",
      "       [-0.2545643 ],\n",
      "       [ 0.09657688],\n",
      "       [-0.5907271 ],\n",
      "       [-0.3129522 ],\n",
      "       [ 0.4836867 ],\n",
      "       [-0.40947697],\n",
      "       [ 0.55355006],\n",
      "       [-0.5887948 ],\n",
      "       [-0.28197318],\n",
      "       [-0.2947401 ],\n",
      "       [ 0.16241087],\n",
      "       [ 0.2072774 ],\n",
      "       [-0.54932785],\n",
      "       [-0.57785416],\n",
      "       [ 0.01406944]], dtype=float32), array([-0.22105423], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "print(all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
