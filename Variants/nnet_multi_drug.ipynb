{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Install TensorFlow\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wes_efgr = pd.read_csv(\"../data/wes_ic50_Erlotinib_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "wes_pacl = pd.read_csv(\"../data/wes_ic50_Paclitaxel_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "wes_suni = pd.read_csv(\"../data/wes_ic50_Sunitinib_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "wes_sora = pd.read_csv(\"../data/wes_ic50_Sorafenib_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "wes_rapa = pd.read_csv(\"../data/wes_ic50_Rapamycin_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "wes_multi_drug = pd.concat([wes_efgr, wes_pacl, wes_suni, wes_sora,wes_rapa], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>101927722</th>\n",
       "      <th>101928638</th>\n",
       "      <th>102724473</th>\n",
       "      <th>102724928</th>\n",
       "      <th>105375355</th>\n",
       "      <th>105378803</th>\n",
       "      <th>107403068</th>\n",
       "      <th>109731405</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>LN_IC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.00000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>371.0</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.0</td>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>0.024259</td>\n",
       "      <td>0.032345</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.03504</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>0.048518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.016173</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.013477</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.464419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>107.242715</td>\n",
       "      <td>0.154059</td>\n",
       "      <td>0.177154</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>0.145449</td>\n",
       "      <td>0.18413</td>\n",
       "      <td>0.051917</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>0.103413</td>\n",
       "      <td>0.215147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>0.073323</td>\n",
       "      <td>0.126309</td>\n",
       "      <td>0.051917</td>\n",
       "      <td>0.145449</td>\n",
       "      <td>0.115462</td>\n",
       "      <td>0.169848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.160602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.132525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>92.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.044453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.661822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>277.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.192688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>370.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.244164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 18384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           1           2           9          10         12  \\\n",
       "count  371.000000  371.000000  371.000000  371.000000  371.000000  371.00000   \n",
       "mean   185.000000    0.024259    0.032345    0.008086    0.021563    0.03504   \n",
       "std    107.242715    0.154059    0.177154    0.089680    0.145449    0.18413   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "25%     92.500000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "50%    185.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "75%    277.500000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "max    370.000000    1.000000    1.000000    1.000000    1.000000    1.00000   \n",
       "\n",
       "               13          14          15          16     ...      101927722  \\\n",
       "count  371.000000  371.000000  371.000000  371.000000     ...          371.0   \n",
       "mean     0.002695    0.008086    0.010782    0.048518     ...            0.0   \n",
       "std      0.051917    0.089680    0.103413    0.215147     ...            0.0   \n",
       "min      0.000000    0.000000    0.000000    0.000000     ...            0.0   \n",
       "25%      0.000000    0.000000    0.000000    0.000000     ...            0.0   \n",
       "50%      0.000000    0.000000    0.000000    0.000000     ...            0.0   \n",
       "75%      0.000000    0.000000    0.000000    0.000000     ...            0.0   \n",
       "max      1.000000    1.000000    1.000000    1.000000     ...            0.0   \n",
       "\n",
       "        101928638   102724473   102724928   105375355   105378803   107403068  \\\n",
       "count  371.000000  371.000000  371.000000  371.000000  371.000000  371.000000   \n",
       "mean     0.008086    0.005391    0.016173    0.002695    0.021563    0.013477   \n",
       "std      0.089680    0.073323    0.126309    0.051917    0.145449    0.115462   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        109731405  DRUG_ID     LN_IC50  \n",
       "count  371.000000    371.0  371.000000  \n",
       "mean     0.029650      1.0    2.464419  \n",
       "std      0.169848      0.0    1.160602  \n",
       "min      0.000000      1.0   -3.132525  \n",
       "25%      0.000000      1.0    2.044453  \n",
       "50%      0.000000      1.0    2.661822  \n",
       "75%      0.000000      1.0    3.192688  \n",
       "max      1.000000      1.0    5.244164  \n",
       "\n",
       "[8 rows x 18384 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wes_efgr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>101928638</th>\n",
       "      <th>102724473</th>\n",
       "      <th>102724928</th>\n",
       "      <th>105375355</th>\n",
       "      <th>105378803</th>\n",
       "      <th>107403068</th>\n",
       "      <th>109731405</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>LN_IC50</th>\n",
       "      <th>BINARY_RESPONSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COSMIC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907268</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.726708</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907269</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.175124</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907270</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.332820</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907271</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.894932</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907273</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.717920</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0    1    2    9   10   12   13   14   15   16  \\\n",
       "COSMIC_ID                                                            \n",
       "907268              0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907269              1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907270              2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907271              3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907273              4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                ...         101928638  102724473  102724928  105375355  \\\n",
       "COSMIC_ID       ...                                                      \n",
       "907268          ...               0.0        0.0        0.0        0.0   \n",
       "907269          ...               0.0        0.0        0.0        0.0   \n",
       "907270          ...               0.0        0.0        0.0        0.0   \n",
       "907271          ...               0.0        0.0        0.0        0.0   \n",
       "907273          ...               0.0        0.0        0.0        0.0   \n",
       "\n",
       "           105378803  107403068  109731405  DRUG_ID   LN_IC50  BINARY_RESPONSE  \n",
       "COSMIC_ID                                                                       \n",
       "907268           0.0        0.0        0.0        1  2.726708                R  \n",
       "907269           0.0        0.0        0.0        1  3.175124                R  \n",
       "907270           0.0        0.0        0.0        1  3.332820                R  \n",
       "907271           0.0        0.0        0.0        1  2.894932                R  \n",
       "907273           0.0        0.0        0.0        1  2.717920                R  \n",
       "\n",
       "[5 rows x 18385 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wes_efgr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    1940\n",
       "1             1940\n",
       "2             1940\n",
       "9             1940\n",
       "10            1940\n",
       "12            1940\n",
       "13            1940\n",
       "14            1940\n",
       "15            1940\n",
       "16            1940\n",
       "18            1940\n",
       "19            1940\n",
       "20            1940\n",
       "21            1940\n",
       "22            1940\n",
       "23            1940\n",
       "24            1940\n",
       "25            1940\n",
       "27            1940\n",
       "29            1940\n",
       "30            1940\n",
       "31            1940\n",
       "32            1940\n",
       "33            1940\n",
       "34            1940\n",
       "35            1940\n",
       "36            1940\n",
       "37            1940\n",
       "38            1940\n",
       "39            1940\n",
       "              ... \n",
       "100506658     1940\n",
       "100506736     1940\n",
       "100506742     1940\n",
       "100506755     1940\n",
       "100506888     1940\n",
       "100507290     1940\n",
       "100507436     1940\n",
       "100507608     1940\n",
       "100507650     1940\n",
       "100526773     1940\n",
       "100526835     1940\n",
       "100528020     1940\n",
       "100533177     1940\n",
       "100533178     1940\n",
       "100652748     1940\n",
       "100652781     1940\n",
       "100996331     1940\n",
       "100996465     1940\n",
       "101060200     1940\n",
       "101060321     1940\n",
       "101927546     1940\n",
       "101927722     1940\n",
       "101928638     1940\n",
       "102724473     1940\n",
       "102724928     1940\n",
       "105375355     1940\n",
       "105378803     1940\n",
       "107403068     1940\n",
       "109731405     1940\n",
       "DRUG_ID       1940\n",
       "Length: 18383, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wes_multi_drug.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "#train_data_set, dev_data_set, train_labels, dev_labels = train_test_split(wes_multi_drug, wes_multi_drug['BINARY_RESPONSE'], test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_data_set, train_labels, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>101928638</th>\n",
       "      <th>102724473</th>\n",
       "      <th>102724928</th>\n",
       "      <th>105375355</th>\n",
       "      <th>105378803</th>\n",
       "      <th>107403068</th>\n",
       "      <th>109731405</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>LN_IC50</th>\n",
       "      <th>BINARY_RESPONSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COSMIC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907268</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.726708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907269</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.175124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907270</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.332820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907271</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.894932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907273</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.717920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0    1    2    9   10   12   13   14   15   16  \\\n",
       "COSMIC_ID                                                            \n",
       "907268              0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907269              1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907270              2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907271              3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907273              4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                ...         101928638  102724473  102724928  105375355  \\\n",
       "COSMIC_ID       ...                                                      \n",
       "907268          ...               0.0        0.0        0.0        0.0   \n",
       "907269          ...               0.0        0.0        0.0        0.0   \n",
       "907270          ...               0.0        0.0        0.0        0.0   \n",
       "907271          ...               0.0        0.0        0.0        0.0   \n",
       "907273          ...               0.0        0.0        0.0        0.0   \n",
       "\n",
       "           105378803  107403068  109731405  DRUG_ID   LN_IC50  BINARY_RESPONSE  \n",
       "COSMIC_ID                                                                       \n",
       "907268           0.0        0.0        0.0        1  2.726708                0  \n",
       "907269           0.0        0.0        0.0        1  3.175124                0  \n",
       "907270           0.0        0.0        0.0        1  3.332820                0  \n",
       "907271           0.0        0.0        0.0        1  2.894932                0  \n",
       "907273           0.0        0.0        0.0        1  2.717920                0  \n",
       "\n",
       "[5 rows x 18385 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wes_multi_drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "wes_multi_drug.loc[(wes_multi_drug.BINARY_RESPONSE == 'S'),'BINARY_RESPONSE'] = 1\n",
    "wes_multi_drug.loc[(wes_multi_drug.BINARY_RESPONSE == 'R'),'BINARY_RESPONSE'] = 0\n",
    "\n",
    "wes_multi_drug = wes_multi_drug.drop('LN_IC50', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = wes_multi_drug.pop('BINARY_RESPONSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>101927546</th>\n",
       "      <th>101927722</th>\n",
       "      <th>101928638</th>\n",
       "      <th>102724473</th>\n",
       "      <th>102724928</th>\n",
       "      <th>105375355</th>\n",
       "      <th>105378803</th>\n",
       "      <th>107403068</th>\n",
       "      <th>109731405</th>\n",
       "      <th>DRUG_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COSMIC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907268</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907269</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907270</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907271</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907273</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0    1    2    9   10   12   13   14   15   16   ...     \\\n",
       "COSMIC_ID                                                            ...      \n",
       "907268              0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...      \n",
       "907269              1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...      \n",
       "907270              2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...      \n",
       "907271              3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...      \n",
       "907273              4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...      \n",
       "\n",
       "           101927546  101927722  101928638  102724473  102724928  105375355  \\\n",
       "COSMIC_ID                                                                     \n",
       "907268           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "907269           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "907270           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "907271           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "907273           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "           105378803  107403068  109731405  DRUG_ID  \n",
       "COSMIC_ID                                            \n",
       "907268           0.0        0.0        0.0        1  \n",
       "907269           0.0        0.0        0.0        1  \n",
       "907270           0.0        0.0        0.0        1  \n",
       "907271           0.0        0.0        0.0        1  \n",
       "907273           0.0        0.0        0.0        1  \n",
       "\n",
       "[5 rows x 18383 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wes_multi_drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((wes_multi_drug.values, target.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat, targ in dataset.take(5):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.shuffle(len(wes_multi_drug)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "500/500 [==============================] - 18s 37ms/step - loss: 0.3645 - acc: 0.8840\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 11s 21ms/step - loss: 0.4682 - acc: 0.8860\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 11s 21ms/step - loss: 0.4649 - acc: 0.8780\n",
      "Epoch 4/15\n",
      "439/500 [=========================>....] - ETA: 1s - loss: 0.4289 - acc: 0.8861WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "440/500 [=========================>....] - ETA: 1s - loss: 0.4283 - acc: 0.8864Epoch 5/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 6/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 7/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 8/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 9/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 10/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 11/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 12/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 13/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 14/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864Epoch 15/15\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need touse the repeat() function when building your dataset.\n",
      "  0/500 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.8864"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a77d76630>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=15, steps_per_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
