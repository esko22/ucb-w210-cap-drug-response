{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Install TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wes_efgr = pd.read_csv(\"../data/wes_ic50_Erlotinib_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "wes_pacl = pd.read_csv(\"../data/wes_ic50_Paclitaxel_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "wes_suni = pd.read_csv(\"../data/wes_ic50_Sunitinib_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "wes_sora = pd.read_csv(\"../data/wes_ic50_Sorafenib_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")\n",
    "wes_rapa = pd.read_csv(\"../data/wes_ic50_Rapamycin_binary_resp.tsv\",sep = \"\\t\", index_col=\"COSMIC_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wes_multi_drug = pd.concat([wes_efgr, wes_pacl, wes_suni, wes_sora,wes_rapa], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>101927722</th>\n",
       "      <th>101928638</th>\n",
       "      <th>102724473</th>\n",
       "      <th>102724928</th>\n",
       "      <th>105375355</th>\n",
       "      <th>105378803</th>\n",
       "      <th>107403068</th>\n",
       "      <th>109731405</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>LN_IC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.00000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>371.0</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.0</td>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>0.024259</td>\n",
       "      <td>0.032345</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.03504</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>0.048518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.016173</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.013477</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.464419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>107.242715</td>\n",
       "      <td>0.154059</td>\n",
       "      <td>0.177154</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>0.145449</td>\n",
       "      <td>0.18413</td>\n",
       "      <td>0.051917</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>0.103413</td>\n",
       "      <td>0.215147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>0.073323</td>\n",
       "      <td>0.126309</td>\n",
       "      <td>0.051917</td>\n",
       "      <td>0.145449</td>\n",
       "      <td>0.115462</td>\n",
       "      <td>0.169848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.160602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.132525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>92.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.044453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.661822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>277.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.192688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>370.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.244164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 18384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           1           2           9          10         12  \\\n",
       "count  371.000000  371.000000  371.000000  371.000000  371.000000  371.00000   \n",
       "mean   185.000000    0.024259    0.032345    0.008086    0.021563    0.03504   \n",
       "std    107.242715    0.154059    0.177154    0.089680    0.145449    0.18413   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "25%     92.500000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "50%    185.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "75%    277.500000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "max    370.000000    1.000000    1.000000    1.000000    1.000000    1.00000   \n",
       "\n",
       "               13          14          15          16     ...      101927722  \\\n",
       "count  371.000000  371.000000  371.000000  371.000000     ...          371.0   \n",
       "mean     0.002695    0.008086    0.010782    0.048518     ...            0.0   \n",
       "std      0.051917    0.089680    0.103413    0.215147     ...            0.0   \n",
       "min      0.000000    0.000000    0.000000    0.000000     ...            0.0   \n",
       "25%      0.000000    0.000000    0.000000    0.000000     ...            0.0   \n",
       "50%      0.000000    0.000000    0.000000    0.000000     ...            0.0   \n",
       "75%      0.000000    0.000000    0.000000    0.000000     ...            0.0   \n",
       "max      1.000000    1.000000    1.000000    1.000000     ...            0.0   \n",
       "\n",
       "        101928638   102724473   102724928   105375355   105378803   107403068  \\\n",
       "count  371.000000  371.000000  371.000000  371.000000  371.000000  371.000000   \n",
       "mean     0.008086    0.005391    0.016173    0.002695    0.021563    0.013477   \n",
       "std      0.089680    0.073323    0.126309    0.051917    0.145449    0.115462   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        109731405  DRUG_ID     LN_IC50  \n",
       "count  371.000000    371.0  371.000000  \n",
       "mean     0.029650      1.0    2.464419  \n",
       "std      0.169848      0.0    1.160602  \n",
       "min      0.000000      1.0   -3.132525  \n",
       "25%      0.000000      1.0    2.044453  \n",
       "50%      0.000000      1.0    2.661822  \n",
       "75%      0.000000      1.0    3.192688  \n",
       "max      1.000000      1.0    5.244164  \n",
       "\n",
       "[8 rows x 18384 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wes_efgr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>101928638</th>\n",
       "      <th>102724473</th>\n",
       "      <th>102724928</th>\n",
       "      <th>105375355</th>\n",
       "      <th>105378803</th>\n",
       "      <th>107403068</th>\n",
       "      <th>109731405</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>LN_IC50</th>\n",
       "      <th>BINARY_RESPONSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COSMIC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907268</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.726708</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907269</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.175124</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907270</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.332820</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907271</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.894932</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907273</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.717920</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0    1    2    9   10   12   13   14   15   16  \\\n",
       "COSMIC_ID                                                            \n",
       "907268              0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907269              1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907270              2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907271              3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907273              4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                ...         101928638  102724473  102724928  105375355  \\\n",
       "COSMIC_ID       ...                                                      \n",
       "907268          ...               0.0        0.0        0.0        0.0   \n",
       "907269          ...               0.0        0.0        0.0        0.0   \n",
       "907270          ...               0.0        0.0        0.0        0.0   \n",
       "907271          ...               0.0        0.0        0.0        0.0   \n",
       "907273          ...               0.0        0.0        0.0        0.0   \n",
       "\n",
       "           105378803  107403068  109731405  DRUG_ID   LN_IC50  BINARY_RESPONSE  \n",
       "COSMIC_ID                                                                       \n",
       "907268           0.0        0.0        0.0        1  2.726708                R  \n",
       "907269           0.0        0.0        0.0        1  3.175124                R  \n",
       "907270           0.0        0.0        0.0        1  3.332820                R  \n",
       "907271           0.0        0.0        0.0        1  2.894932                R  \n",
       "907273           0.0        0.0        0.0        1  2.717920                R  \n",
       "\n",
       "[5 rows x 18385 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wes_efgr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    1940\n",
       "1             1940\n",
       "2             1940\n",
       "9             1940\n",
       "10            1940\n",
       "12            1940\n",
       "13            1940\n",
       "14            1940\n",
       "15            1940\n",
       "16            1940\n",
       "18            1940\n",
       "19            1940\n",
       "20            1940\n",
       "21            1940\n",
       "22            1940\n",
       "23            1940\n",
       "24            1940\n",
       "25            1940\n",
       "27            1940\n",
       "29            1940\n",
       "30            1940\n",
       "31            1940\n",
       "32            1940\n",
       "33            1940\n",
       "34            1940\n",
       "35            1940\n",
       "36            1940\n",
       "37            1940\n",
       "38            1940\n",
       "39            1940\n",
       "              ... \n",
       "100506658     1940\n",
       "100506736     1940\n",
       "100506742     1940\n",
       "100506755     1940\n",
       "100506888     1940\n",
       "100507290     1940\n",
       "100507436     1940\n",
       "100507608     1940\n",
       "100507650     1940\n",
       "100526773     1940\n",
       "100526835     1940\n",
       "100528020     1940\n",
       "100533177     1940\n",
       "100533178     1940\n",
       "100652748     1940\n",
       "100652781     1940\n",
       "100996331     1940\n",
       "100996465     1940\n",
       "101060200     1940\n",
       "101060321     1940\n",
       "101927546     1940\n",
       "101927722     1940\n",
       "101928638     1940\n",
       "102724473     1940\n",
       "102724928     1940\n",
       "105375355     1940\n",
       "105378803     1940\n",
       "107403068     1940\n",
       "109731405     1940\n",
       "DRUG_ID       1940\n",
       "Length: 18383, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wes_multi_drug.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(18384,)),\n",
    "  tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_data_set, train_labels, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>101928638</th>\n",
       "      <th>102724473</th>\n",
       "      <th>102724928</th>\n",
       "      <th>105375355</th>\n",
       "      <th>105378803</th>\n",
       "      <th>107403068</th>\n",
       "      <th>109731405</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>LN_IC50</th>\n",
       "      <th>BINARY_RESPONSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COSMIC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907268</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.726708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907269</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.175124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907270</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.332820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907271</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.894932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907273</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.717920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0    1    2    9   10   12   13   14   15   16  \\\n",
       "COSMIC_ID                                                            \n",
       "907268              0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907269              1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907270              2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907271              3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "907273              4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                ...         101928638  102724473  102724928  105375355  \\\n",
       "COSMIC_ID       ...                                                      \n",
       "907268          ...               0.0        0.0        0.0        0.0   \n",
       "907269          ...               0.0        0.0        0.0        0.0   \n",
       "907270          ...               0.0        0.0        0.0        0.0   \n",
       "907271          ...               0.0        0.0        0.0        0.0   \n",
       "907273          ...               0.0        0.0        0.0        0.0   \n",
       "\n",
       "           105378803  107403068  109731405  DRUG_ID   LN_IC50  BINARY_RESPONSE  \n",
       "COSMIC_ID                                                                       \n",
       "907268           0.0        0.0        0.0        1  2.726708                0  \n",
       "907269           0.0        0.0        0.0        1  3.175124                0  \n",
       "907270           0.0        0.0        0.0        1  3.332820                0  \n",
       "907271           0.0        0.0        0.0        1  2.894932                0  \n",
       "907273           0.0        0.0        0.0        1  2.717920                0  \n",
       "\n",
       "[5 rows x 18385 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wes_multi_drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wes_multi_drug.loc[(wes_multi_drug.BINARY_RESPONSE == 'S'),'BINARY_RESPONSE'] = 1\n",
    "wes_multi_drug.loc[(wes_multi_drug.BINARY_RESPONSE == 'R'),'BINARY_RESPONSE'] = 0\n",
    "\n",
    "wes_multi_drug = wes_multi_drug.drop('LN_IC50', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_data_set, dev_data_set, train_labels, dev_labels = train_test_split(wes_multi_drug, wes_multi_drug['BINARY_RESPONSE'], test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = wes_multi_drug.pop('BINARY_RESPONSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data_set.values, train_labels.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat, targ in dataset.take(5):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(len(train_data_set)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 90 steps\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 1.2138 - accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 1.7346 - accuracy: 0.8778\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6334 - accuracy: 0.8667\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7109 - accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6363 - accuracy: 0.8444\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6483 - accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.9348 - accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7096 - accuracy: 0.8556\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.3771 - accuracy: 0.8778\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5178 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a348a2110>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10, steps_per_epoch=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((dev_data_set.values, dev_labels.values))\n",
    "test_dataset = test_dataset.shuffle(len(dev_data_set)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 - 1s - loss: 0.4117 - accuracy: 0.8866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4116630472540849, 0.88659793]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset, verbose=2, steps=len(dev_data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 18384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2353280   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,354,570\n",
      "Trainable params: 2,354,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kbloom/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: wes_multi_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('wes_multi_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 18384)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               2353280   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,354,570\n",
      "Trainable params: 2,354,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('wes_multi_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model = tf.keras.Sequential()\n",
    "another_model.add(new_model)\n",
    "#another_model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "#another_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "another_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_9 (Sequential)    (None, 10)                2354570   \n",
      "=================================================================\n",
      "Total params: 2,354,570\n",
      "Trainable params: 2,354,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "another_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'dense_21_target_1' with dtype int32 and shape [?,?]\n\t [[{{node dense_21_target_1}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-44a3887af64c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manother_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m           \u001b[0;31m# `ins` can be callable in DistributionStrategy + eager case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           logging.warning('Your dataset iterator ran out of data; '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'dense_21_target_1' with dtype int32 and shape [?,?]\n\t [[{{node dense_21_target_1}}]]"
     ]
    }
   ],
   "source": [
    "another_model.fit(train_dataset, epochs=10, steps_per_epoch=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_url = \"wes_multi_model/\"\n",
    "embed = hub.KerasLayer(hub_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotha_model = tf.keras.Sequential([\n",
    "    embed,\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotha_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train for 90 steps\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.8286 - accuracy: 0.1222\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.9111\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8333\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8889\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8556\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.9000\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.9111\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a389fb150>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotha_model.fit(train_dataset, epochs=10, steps_per_epoch=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 - 1s - loss: 0.3364 - accuracy: 0.8918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3364413761793031, 0.8917526]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotha_model.evaluate(test_dataset, verbose=2, steps=len(dev_data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
